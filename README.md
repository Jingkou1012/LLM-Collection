<p align="center">
  <img src="https://github.com/Jingkou1012/LLM-Collection/blob/main/Title-Img.jpg">
</p>

## LLM-Paper

> The limits of my language mean the limites of my world. - Ludwig Wittgenstein

This repository serves as a central hub for all things related to Large Language Models (LLMs). Whether you‚Äôre a researcher, developer, or simply curious about LLMs, you‚Äôll find valuable content here to enhance your understanding and work with these remarkable language models. 

---
## üéì Overview
- 230331 - RUCAIBox - Survey - A Survey of Large Language Models - [arXiv](https://arxiv.org/abs/2303.18223)
---
## üëë Transformer Related
- 170612 - Google - Transformer - Attention is All You Need - [arXiv](https://arxiv.org/abs/1706.03762)
- 181011 - Google - BERT - Pre-Training of Deep Bidirectional Transformers for Language Understanding - [arXiv](https://arxiv.org/abs/1810.04805)
- 201022 - Google - ViT - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale - [arXiv](https://arxiv.org/abs/2010.11929)
---
## üß† Large Language Model
- 180611 - OpenAI - GPT -  Improving Language Understanding by Generative Pre-Training - [report](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
- 190214 - OpenAI - GPT-2 - Language Models are Unsupervised Multitask Learners - [report](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- 200528 - OpenAI - GPT-3 - Language Models are Few-Shot Learners - [arXiv](https://arxiv.org/abs/2005.14165)
- 210226 - OpenAI - CLIP - Learning Transferable Visual Models From Natural Language Supervision - [arXiv](https://arxiv.org/abs/2103.00020)
- 230227 - Meta - Llama - Open and Efficient Foundation Language Models - [arXiv](https://arxiv.org/abs/2302.13971)
- 230315 - OpenAI - GPT-4 - GPT-4 Technical Report - [arXiv](https://arxiv.org/abs/2303.08774)
- 230718 - Meta - Llama 2 - Open Foundation and Fine-Tuned Chat Models - [arXiv](https://arxiv.org/abs/2307.09288)
- 231219 - Google - Gemini - A Family of Highly Capable Multimodal Models - [arXiv](https://arxiv.org/abs/2312.11805)
- 240221 - Google - Gemma - Open Models Based on Gemini Research and Technology - [report](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)
- 240308 - Google - Gemini 1.5 - Unlocking Multimodal Understanding across Millions of Tokens of Context - [arXiv](https://arxiv.org/abs/2403.05530)
- 240418 - Meta - Llama 3 - Introducing Meta Llama 3: The most capable openly available LLM to date - [blog](https://ai.meta.com/blog/meta-llama-3/)
- 240513 - OpenAI - GPT-4o - Hello GPT-4o - [page](https://openai.com/index/hello-gpt-4o/)
- 240627 - Google - Gemma 2 - Improving Open Language Models at a Practical Size - [report](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf)
---
## üìè Fine-Tuning
- 210617 - Microsoft - LoRA - Low-Rank Adaptation of Large Language Models - [arXiv](https://arxiv.org/abs/2106.09685)
- 230523 - University of Washington - QLoRA - Efficient Finetuning of Quantized LLMs - [arXiv](https://arxiv.org/abs/2305.14314)
---
## üë®‚Äçüè´ Reinforcement Learning from Human Feedback
- 170612 - OpenAI & Google - Reinforcement Learning - Deep Reinforcement Learning from Human Preferences - [arXiv](https://arxiv.org/abs/1706.03741)
- 200902 - OpenAI - Human Feedback - Learning to Summarize from Human Feedback - [arXiv](https://arxiv.org/abs/2009.01325)
- 220304 - OpenAI - InstructGPT - Training Language Models to Follow Instructions with Human Feedback - [arXiv](https://arxiv.org/abs/2203.02155)
---
## üìö Retrieval Augmented Generation
- 200522 - Facebook - RAG - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks - [arXiv](https://arxiv.org/abs/2005.11401)
- 240424 - Microsoft - Graph RAG - From Local to Global: A Graph RAG Approach to Query-Focused Summarization - [arXiv](https://arxiv.org/abs/2404.16130)
---
## üì∑ Vision Large Model
- 230417 - Haotian Liu - LLaVA - Visual Instruction Tuning - [arXiv](https://arxiv.org/abs/2304.08485)
- 230925 - OpenAI - GPT-4V - GPT-4V(ision) System Card - [report](https://cdn.openai.com/papers/GPTV_System_Card.pdf)
- 231005 - Haotian Liu - LLaVA 1.5 - Improved Baselines with Visual Instruction Tuning - [arXiv](https://arxiv.org/abs/2310.03744)
- 240130 - Haotian Liu - LLaVA-NeXT - Improved Reasoning, OCR, and World Knowledge - [blog](https://llava-vl.github.io/blog/2024-01-30-llava-next/)
- 240514 - Google - PaliGemma - Google's Cutting-Edge Open Vision Language Model - [blog](https://huggingface.co/blog/paligemma)
---
## üöó Autonomous Driving
- 221220 - OpenDriveLab - UniAD - Planning-Oriented Autonomous Driving - [arXiv](https://arxiv.org/abs/2212.10156)
- 240219 - Tsinghua - DriveVLM - The Convergence of Autonomous Driving and Large Vision-Language Models - [arXiv](https://arxiv.org/abs/2402.12289)
---
## üõ†Ô∏è Deployment

- Llama Recipes - Scripts for fine-tuning Meta Llama3 with composable FSDP & PEFT methods - [![GitHub Repo stars](https://img.shields.io/github/stars/meta-llama/llama-recipes?style=social)](https://github.com/meta-llama/llama-recipes)
- DeepSpeed - An optimization library that makes distributed training and inference easy, efficient, and effective. - [![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/DeepSpeed?style=social)](https://github.com/microsoft/DeepSpeed)
- unsloth - Finetune Llama 3, Mistral, Phi & Gemma LLMs 2-5x faster with 80% less memory - [![GitHub Repo stars](https://img.shields.io/github/stars/unslothai/unsloth?style=social)](https://github.com/unslothai/unsloth)
- Evals - A framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks - [![GitHub Repo stars](https://img.shields.io/github/stars/openai/evals?style=social)](https://github.com/openai/evals)
- RAGFlow - RAGFlow is an open-source RAG engine based on deep document understanding. [![GitHub Repo stars](https://img.shields.io/github/stars/infiniflow/ragflow?style=social)](https://github.com/infiniflow/ragflow)
- GraphRAG - A modular graph-based Retrieval-Augmented Generation (RAG) system - [![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/graphrag?style=social)](https://github.com/microsoft/graphrag)
- Dify - Dify is an open-source LLM app development platform. - [![GitHub Repo stars](https://img.shields.io/github/stars/langgenius/dify?style=social)](https://github.com/langgenius/dify)
- vLLM - A high-throughput and memory-efficient inference and serving engine for LLMs - [![GitHub Repo stars](https://img.shields.io/github/stars/vllm-project/vllm?style=social)](https://github.com/vllm-project/vllm)
- Ollama - Get up and running with large language models - [![GitHub Repo stars](https://img.shields.io/github/stars/ollama/ollama?style=social)](https://github.com/ollama/ollama)
- llama.cpp - LLM inference in C/C++ - [![GitHub Repo stars](https://img.shields.io/github/stars/ggerganov/llama.cpp?style=social)](https://github.com/ggerganov/llama.cpp)
- LLaMA-Factory - A WebUI for Efficient Fine-Tuning of 100+ LLMs - [![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)](https://github.com/hiyouga/LLaMA-Factory)
- LangChain - Build context-aware reasoning applications - [![GitHub Repo stars](https://img.shields.io/github/stars/langchain-ai/langchain?style=social)](https://github.com/langchain-ai/langchain)
- Open WebUI - User-friendly WebUI for LLMs (Formerly Ollama WebUI) - [![GitHub Repo stars](https://img.shields.io/github/stars/open-webui/open-webui?style=social)](https://github.com/open-webui/open-webui)

---
## üí≠ Deep Dive
- Lil'Log - [blog](https://lilianweng.github.io/)
- Open LLM Leaderboard - [HF](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)
---
## ‚ô•Ô∏è Contributing

This project holds great significance for me, and I‚Äôm constantly seeking ways to improve it. If you have ideas, fixes, or even just suggestions, please share them! I‚Äôm open to discussing any pull requests, especially if we need to align them with the LLM‚Äôs goals.

Thansk a lot!

---
## ‚≠ê Star History
[![Star History Chart](https://api.star-history.com/svg?repos=Jingkou1012/LLM-Collection&type=Date)](https://star-history.com/#Jingkou1012/LLM-Collection&Date)
