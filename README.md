<p align="center">
  <img src="https://github.com/Jingkou1012/LLM-Collection/blob/main/Title-Img.jpg">
</p>

## LLM-Collection

> The limits of my language mean the limites of my world. - Ludwig Wittgenstein

This repository serves as a central hub for all things related to Large Language Models (LLMs). Whether you‚Äôre a researcher, developer, or simply curious about LLMs, you‚Äôll find valuable content here to enhance your understanding and work with these remarkable language models. 

---
## üéì Overview
- 230331 - RUCAIBox - Survey - A Survey of Large Language Models - [arXiv](https://arxiv.org/abs/2303.18223)
---
## üëë Transformer Related
- 170612 - Google - Transformer - Attention is All You Need - [arXiv](https://arxiv.org/abs/1706.03762)
- 181011 - Google - BERT - Pre-Training of Deep Bidirectional Transformers for Language Understanding - [arXiv](https://arxiv.org/abs/1810.04805)
- 201022 - Google - ViT - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale - [arXiv](https://arxiv.org/abs/2010.11929)
---
## üß† Large Language Model
- 180611 - OpenAI - GPT -  Improving Language Understanding by Generative Pre-Training - [report](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
- 190214 - OpenAI - GPT-2 - Language Models are Unsupervised Multitask Learners - [report](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- 200528 - OpenAI - GPT-3 - Language Models are Few-Shot Learners - [arXiv](https://arxiv.org/abs/2005.14165)
- 210226 - OpenAI - CLIP - Learning Transferable Visual Models From Natural Language Supervision - [arXiv](https://arxiv.org/abs/2103.00020)
- 230227 - Meta - Llama - Open and Efficient Foundation Language Models - [arXiv](https://arxiv.org/abs/2302.13971)
- 230315 - OpenAI - GPT-4 - GPT-4 Technical Report - [arXiv](https://arxiv.org/abs/2303.08774)
- 230718 - Meta - Llama 2 - Open Foundation and Fine-Tuned Chat Models - [arXiv](https://arxiv.org/abs/2307.09288)
- 231219 - Google - Gemini - A Family of Highly Capable Multimodal Models - [arXiv](https://arxiv.org/abs/2312.11805)
- 240221 - Google - Gemma - Open Models Based on Gemini Research and Technology - [report](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)
- 240308 - Google - Gemini 1.5 - Unlocking Multimodal Understanding across Millions of Tokens of Context - [arXiv](https://arxiv.org/abs/2403.05530)
- 240418 - Meta - Llama 3 - Introducing Meta Llama 3: The most capable openly available LLM to date - [blog](https://ai.meta.com/blog/meta-llama-3/)
- 240513 - OpenAI - GPT-4o - Hello GPT-4o - [page](https://openai.com/index/hello-gpt-4o/)
- 240627 - Google - Gemma 2 - Improving Open Language Models at a Practical Size - [report](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf)
---
## üìè Fine-Tuning
- 210617 - Microsoft - LoRA - Low-Rank Adaptation of Large Language Models - [arXiv](https://arxiv.org/abs/2106.09685)
- 230523 - University of Washington - QLoRA - Efficient Finetuning of Quantized LLMs - [arXiv](https://arxiv.org/abs/2305.14314)
---
## üë®‚Äçüè´ Reinforcement Learning from Human Feedback
- 170612 - OpenAI & Google - Reinforcement Learning - Deep Reinforcement Learning from Human Preferences - [arXiv](https://arxiv.org/abs/1706.03741)
- 200902 - OpenAI - Human Feedback - Learning to Summarize from Human Feedback - [arXiv](https://arxiv.org/abs/2009.01325)
- 220304 - OpenAI - InstructGPT - Training Language Models to Follow Instructions with Human Feedback - [arXiv](https://arxiv.org/abs/2203.02155)
---
## üìö Retrieval Augmented Generation
- 200522 - Facebook - RAG - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks - [arXiv](https://arxiv.org/abs/2005.11401)
- 240424 - Microsoft - Graph RAG - From Local to Global: A Graph RAG Approach to Query-Focused Summarization - [arXiv](https://arxiv.org/abs/2404.16130)
---
## üì∑ Vision Large Model
- 230417 - Haotian Liu - LLaVA - Visual Instruction Tuning - [arXiv](https://arxiv.org/abs/2304.08485)
- 230925 - OpenAI - GPT-4V - GPT-4V(ision) System Card - [report](https://cdn.openai.com/papers/GPTV_System_Card.pdf)
- 231005 - Haotian Liu - LLaVA 1.5 - Improved Baselines with Visual Instruction Tuning - [arXiv](https://arxiv.org/abs/2310.03744)
- 240130 - Haotian Liu - LLaVA-NeXT - Improved Reasoning, OCR, and World Knowledge - [blog](https://llava-vl.github.io/blog/2024-01-30-llava-next/)
- 240514 - Google - PaliGemma - Google's Cutting-Edge Open Vision Language Model - [blog](https://huggingface.co/blog/paligemma)
---
## üöó Autonomous Driving
- 221220 - OpenDriveLab - UniAD - Planning-Oriented Autonomous Driving - [arXiv](https://arxiv.org/abs/2212.10156)
- 240219 - Tsinghua - DriveVLM - The Convergence of Autonomous Driving and Large Vision-Language Models - [arXiv](https://arxiv.org/abs/2402.12289)
---
## üõ†Ô∏è Deployment

- Ollama - Get up and running with large language models - [![GitHub Repo stars](https://img.shields.io/github/stars/ollama/ollama?style=social)](https://github.com/ollama/ollama)
- LangChain - Build context-aware reasoning applications - [![GitHub Repo stars](https://img.shields.io/github/stars/langchain-ai/langchain?style=social)](https://github.com/langchain-ai/langchain)

---
## üí≠ Deep Dive
- Lil'Log - [blog](https://lilianweng.github.io/)
- Open LLM Leaderboard - [HF](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)
---
## ‚ô•Ô∏è Contributing

This project holds great significance for me, and I‚Äôm constantly seeking ways to improve it. If you have ideas, fixes, or even just suggestions, please share them! I‚Äôm open to discussing any pull requests, especially if we need to align them with the LLM‚Äôs goals.

Thansk a lot!

---
## ‚≠ê Star History
[![Star History Chart](https://api.star-history.com/svg?repos=Jingkou1012/LLM-Collection&type=Date)](https://star-history.com/#Jingkou1012/LLM-Collection&Date)
