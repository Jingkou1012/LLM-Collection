# LLM-Collection

> The limits of my language mean the limites of my world. - Ludwig Wittgenstein

This repository serves as a hub for all things related to Large Language Models. Whether you‚Äôre a researcher, developer, or just curious about LLMs, you‚Äôll find valuable content here to help you understand and work with these incredible language models. Let‚Äôs learn together and push the boundaries of language understanding!

---
## üéì Overview
- 230331 - RUCAIBox - Survey - A Survey of Large Language Models - [arXiv](https://arxiv.org/abs/2303.18223)
---
## üëë Transformer
- 170612 - Google - Transformer - Attention is All You Need - [arXiv](https://arxiv.org/abs/1706.03762)
- 181011 - Google - BERT - Bidirectional Encoder Representations from Transformers - [arXiv](https://arxiv.org/abs/1810.04805)
- 201022 - Google - ViT - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale - [arXiv](https://arxiv.org/abs/2010.11929)
---
## üß† Large Language Model
- 180611 - OpenAI - GPT -  Improving Language Understanding by Generative Pre-Training - [report](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
- 190214 - OpenAI - GPT-2 - Language Models are Unsupervised Multitask Learners - [report](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- 200528 - OpenAI - GPT-3 - Language Models are Few-Shot Learners - [arXiv](https://arxiv.org/abs/2005.14165)
- 210226 - OpenAI - CLIP - Learning Transferable Visual Models From Natural Language Supervision - [arXiv](https://arxiv.org/abs/2103.00020)
- 230227 - Meta - Llama - Open and Efficient Foundation Language Models - [arXiv](https://arxiv.org/abs/2302.13971)
- 230315 - OpenAI - GPT-4 - GPT-4 Technical Report - [arXiv](https://arxiv.org/abs/2303.08774)
- 230718 - Meta - Llama 2 - Open Foundation and Fine-Tuned Chat Models - [arXiv](https://arxiv.org/abs/2307.09288)
- 231219 - Google - Gemini - A Family of Highly Capable Multimodal Models - [arXiv](https://arxiv.org/abs/2312.11805)
- 240221 - Google - Gemma - Open Models Based on Gemini Research and Technology - [report](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)
- 240308 - Google - Gemini 1.5 - Unlocking Multimodal Understanding across Millions of Tokens of Context - [arXiv](https://arxiv.org/abs/2403.05530)
- 240418 - Meta - Llama 3 - Introducing Meta Llama 3: The most capable openly available LLM to date - [blog](https://ai.meta.com/blog/meta-llama-3/)
- 240513 - OpenAI - GPT-4o - Hello GPT-4o - [page](https://openai.com/index/hello-gpt-4o/)
- 240627 - Google - Gemma 2 - Improving Open Language Models at a Practical Size - [report](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf)
---
## üìè Fine-tuning

---
## üìö Retrieval Augmented Generation

---
## üì∑ Vision Large Model
- 230417 - Haotian Liu - LLaVA - Visual Instruction Tuning - [arXiv](https://arxiv.org/abs/2304.08485)
- 230925 - OpenAI - GPT-4V - GPT-4V(ision) System Card - [report](https://cdn.openai.com/papers/GPTV_System_Card.pdf)
- 231005 - Haotian Liu - LLaVA 1.5 - Improved Baselines with Visual Instruction Tuning - [arXiv](https://arxiv.org/abs/2310.03744)
- 240130 - Haotian Liu - LLaVA-NeXT - Improved Reasoning, OCR, and World Knowledge - [blog](https://llava-vl.github.io/blog/2024-01-30-llava-next/)
- 240514 - Google - PaliGemma - Google's Cutting-Edge Open Vision Language Model - [blog](https://huggingface.co/blog/paligemma)
---
## üöó Autonomous Driving
- 221220 - OpenDriveLab - UniAD - Planning-Oriented Autonomous Driving - [arXiv](https://arxiv.org/abs/2212.10156)
- 240219 - Tsinghua - DriveVLM - The Convergence of Autonomous Driving and Large Vision-Language Models - [arXiv](https://arxiv.org/abs/2402.12289)
---
## ‚ô•Ô∏è Contributing
This repository is a living, breathing project, and your contributions are what keep it thriving!

If you've got an idea, a fix, or even just a suggestion, don't hesitate to submit a pull request. I'll keep some pull requests open for discussion, especially if I'm not quite sure if they're a perfect fit for the LLM.

Your feedback and contributions are invaluable in shaping the future of this project.  Let's collaborate and make this repository the best it can be!

---
## ‚≠ê Star History
[![Star History Chart](https://api.star-history.com/svg?repos=Jingkou1012/LLM-Collection&type=Date)](https://star-history.com/#Jingkou1012/LLM-Collection&Date)
